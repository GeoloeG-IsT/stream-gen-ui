---
phase: 04-backend-marker-strategy
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - backend/agent/prompts.py
  - backend/agent/graph.py
  - backend/main.py
autonomous: true

must_haves:
  truths:
    - "Agent outputs XML format when marker=xml"
    - "Agent outputs llm-ui format when marker=llm-ui"
    - "Contact entities have all required fields in correct format"
    - "CalendarEvent entities have all required fields in correct format"
  artifacts:
    - path: "backend/agent/prompts.py"
      provides: "Marker-aware prompt templates"
      contains: "def get_agent_prompt(marker:"
    - path: "backend/agent/graph.py"
      provides: "Request-scoped graph creation"
      contains: "def create_agent_graph(marker:"
  key_links:
    - from: "backend/main.py"
      to: "backend/agent/graph.py"
      via: "marker param in create_agent_graph call"
      pattern: "create_agent_graph.*marker"
    - from: "backend/agent/graph.py"
      to: "backend/agent/prompts.py"
      via: "marker param in get_agent_prompt call"
      pattern: "get_agent_prompt.*marker"
---

<objective>
Implement marker-aware prompt system so agent outputs entities in requested format

Purpose: Backend produces correctly formatted entities that frontend renderers can parse (XML tags for Streamdown, Chinese brackets for llm-ui)
Output: Agent that adapts its output format based on marker parameter
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-backend-marker-strategy/04-CONTEXT.md
@.planning/phases/04-backend-marker-strategy/04-RESEARCH.md
@.planning/phases/04-backend-marker-strategy/04-01-SUMMARY.md

# Key source files
@backend/agent/prompts.py
@backend/agent/graph.py
@backend/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create marker-aware prompt templates</name>
  <files>backend/agent/prompts.py</files>
  <action>
Refactor prompts.py to support marker-specific entity formatting. Keep existing prompt structure, just change entity format sections.

1. Create entity format templates as constants:

```python
XML_CONTACT_FORMAT = """When providing contact information, format EACH contact as:

<contactcard name="Full Name" email="email@berlin.de" phone="+49 30 ..." company="Department Name" title="Job Title" />

Include only attributes that have data. Omit missing attributes entirely.
Show TOP 3 most relevant contacts. If more exist, mention: "...and X more contacts available."
"""

XML_EVENT_FORMAT = """When providing event information, format EACH event as:

<calendarevent title="Event Name" date="2026-01-25" time="14:00" location="Venue Address" description="Brief description" />

Include only attributes that have data. Date is required, time and location are optional.
Show TOP 3 upcoming/relevant events. If more exist, mention: "...and X more events found."
"""

LLMUI_CONTACT_FORMAT = """When providing contact information, format EACH contact as:

【CONTACT:{"name": "Full Name", "email": "email@berlin.de", "phone": "+49 30 ...", "company": "Department Name", "title": "Job Title"}】

Include only fields that have data. Omit missing fields entirely (don't include null values).
Show TOP 3 most relevant contacts. If more exist, mention: "...and X more contacts available."
"""

LLMUI_EVENT_FORMAT = """When providing event information, format EACH event as:

【CALENDAR:{"title": "Event Name", "date": "2026-01-25", "time": "14:00", "location": "Venue Address", "description": "Brief description"}】

Include only fields that have data. Date is required, time and location are optional.
Show TOP 3 upcoming/relevant events. If more exist, mention: "...and X more events found."
"""
```

2. Create base prompt template (shared parts):

```python
AGENT_SYSTEM_PROMPT_BASE = """You are a helpful assistant for Berlin city information.

You have access to a knowledge base tool that contains:
- Contact information for city employees and departments
- Upcoming events and city calendar
- General city services and information

## When to use the knowledge base

Use the search_knowledge_base tool when the user asks about:
- Specific people's contact details (emails, phone numbers, addresses)
- Department or agency information
- Events, festivals, or calendar information
- City services, facilities, or procedures

Do NOT use the tool for:
- General greetings or small talk ("Hi", "How are you?")
- Questions about yourself or your capabilities
- Math calculations or reasoning tasks
- Topics unrelated to Berlin city

## How to present information

### Contacts
{contact_format}

### Events
{event_format}

### Mixing entities
You can freely mix contacts and events in a single response when relevant.
Add brief context before and after entities to make the response conversational.

## Tone and style

- Be concise and helpful
- Use brief reasoning: "Looking up Parks department contacts..." not lengthy explanations
- Admit when you don't know: "I couldn't find specific information about that. Try asking about city contacts, events, or services."
- If the knowledge base fails: "I'm having trouble accessing the knowledge base right now. Please try again."

## Error handling

- If no results: Suggest related topics they could ask about
- If partial data: Show what's available, note what's missing
- Never make up information not from the knowledge base
"""
```

3. Update get_agent_prompt to accept marker:

```python
def get_agent_prompt(marker: str = "xml") -> ChatPromptTemplate:
    """Get the agent prompt template for the specified marker strategy.

    Args:
        marker: Output format - "xml" or "llm-ui"

    Returns:
        ChatPromptTemplate with marker-specific entity formatting instructions.
    """
    if marker == "llm-ui":
        contact_format = LLMUI_CONTACT_FORMAT
        event_format = LLMUI_EVENT_FORMAT
    else:  # default to xml
        contact_format = XML_CONTACT_FORMAT
        event_format = XML_EVENT_FORMAT

    system_prompt = AGENT_SYSTEM_PROMPT_BASE.format(
        contact_format=contact_format,
        event_format=event_format
    )

    return ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("placeholder", "{messages}"),
    ])
```

4. Remove or deprecate old AGENT_SYSTEM_PROMPT constant (or keep for backwards compat).
  </action>
  <verify>
Test prompt generation:
```python
cd backend && python -c "
from agent.prompts import get_agent_prompt
xml_prompt = get_agent_prompt('xml')
llmui_prompt = get_agent_prompt('llm-ui')
print('XML has contactcard:', '<contactcard' in str(xml_prompt))
print('LLMUI has CONTACT:', '【CONTACT:' in str(llmui_prompt))
"
```
  </verify>
  <done>
- get_agent_prompt(marker) returns marker-specific prompt
- XML format uses `<contactcard />` and `<calendarevent />` tags
- llm-ui format uses `【CONTACT:{...}】` and `【CALENDAR:{...}】` delimiters
- All entity fields documented (name, email, phone, company, title for contacts; title, date, time, location, description for events)
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire marker through agent graph and endpoint</name>
  <files>backend/agent/graph.py, backend/main.py</files>
  <action>
1. Update graph.py create_agent_graph to accept marker:

```python
def create_agent_graph(marker: str = "xml"):
    """Create and compile the ReAct agent graph.

    Args:
        marker: Output format strategy ("xml" or "llm-ui")

    Returns:
        Compiled LangGraph state machine ready for streaming execution.
    """
    settings = get_settings()

    # ... LLM init stays the same ...

    # Create prompt chain with marker-aware prompt
    prompt = get_agent_prompt(marker)  # Pass marker here
    agent_chain = prompt | llm_with_tools

    # ... rest of function stays the same ...
```

2. Remove singleton pattern - graphs are now request-scoped:

```python
# Remove: _agent_graph = None
# Remove: get_agent_graph() singleton function

# Keep create_agent_graph(marker) as the public API
```

3. Update main.py stream_agent_response to accept and use marker:

```python
async def stream_agent_response(messages: list, message_id: str, marker: str):
    """Stream agent response token-by-token.

    Args:
        messages: List of LangChain message objects
        message_id: Unique ID for the streamed message
        marker: Output format strategy
    """
    # Create request-scoped graph with marker
    graph = create_agent_graph(marker)
    recursion_limit = get_recursion_limit()

    # ... rest stays the same ...
```

4. Update chat_stream endpoint to pass marker:

```python
return StreamingResponse(
    stream_agent_response(lc_messages, message_id, marker),  # Add marker
    media_type="text/event-stream",
    headers={**SSE_HEADERS, "X-Marker-Strategy": marker},
)
```

5. Update imports in main.py:
   - Change: `from agent import get_agent_graph, get_recursion_limit`
   - To: `from agent import create_agent_graph, get_recursion_limit`

6. Update agent/__init__.py exports if needed:
   - Export `create_agent_graph` instead of `get_agent_graph`

7. Update lifespan function in main.py to test graph creation:

```python
# Change from:
get_agent_graph()
# To:
create_agent_graph("xml")  # Test with default marker
```
  </action>
  <verify>
1. Backend starts: `cd backend && python -c "from main import app; print('OK')"`
2. Graph creation works: `cd backend && python -c "from agent import create_agent_graph; g = create_agent_graph('llm-ui'); print('OK')"`
3. Live test with curl (requires running server):
   - Ask about contacts with marker=xml, verify response has `<contactcard` tags
   - Ask about contacts with marker=llm-ui, verify response has `【CONTACT:` delimiters
  </verify>
  <done>
- create_agent_graph(marker) creates marker-aware graph
- Singleton pattern removed (request-scoped graphs)
- stream_agent_response accepts and uses marker
- Agent outputs match requested format
  </done>
</task>

</tasks>

<verification>
1. Backend starts without import errors
2. Prompt templates contain correct format for each marker
3. Live test: `curl -X POST "http://localhost:8000/api/chat?marker=xml" -H "Content-Type: application/json" -d '{"messages":[{"role":"user","content":"Who is in the Parks department?"}]}'` - response contains `<contactcard` tags
4. Live test: `curl -X POST "http://localhost:8000/api/chat?marker=llm-ui" ...` - response contains `【CONTACT:` delimiters
5. Default (no marker) uses xml format
</verification>

<success_criteria>
- Agent outputs `<contactcard name="..." email="..." />` when marker=xml
- Agent outputs `<calendarevent title="..." date="..." />` when marker=xml
- Agent outputs `【CONTACT:{"name":"...","email":"..."}】` when marker=llm-ui
- Agent outputs `【CALENDAR:{"title":"...","date":"..."}】` when marker=llm-ui
- Requirements MARK-01, MARK-02, MARK-03, MARK-04 all satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/04-backend-marker-strategy/04-02-SUMMARY.md`
</output>
